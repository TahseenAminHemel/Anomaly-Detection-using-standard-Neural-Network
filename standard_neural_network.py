# -*- coding: utf-8 -*-
"""Standard Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1819EIIR6Z7i2xbnrNi4tAh_Ul71BZ8f2
"""

# importhing necessary library files

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

# mounting the google drive

from google.colab import drive
drive.mount('/content/drive/')

# Loading the data in the Pandas data frame

data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/MRP/creditcard.csv')

# Splitting the data in test train split

from sklearn.model_selection import train_test_split
X = data.drop('Class',axis=1).values
y = data['Class'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)

# Normalizing the data

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# importing necessary library for neural network

import keras
import tensorflow as tf
from keras import models, layers
from keras.layers import Dense
from keras.utils import np_utils
from keras.models import Sequential

# Defining the neural network model

def create_model():
  return tf.keras.models.Sequential([
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(25, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(units=1,activation='sigmoid')
  ])

# compiling the model

mymodel = create_model()
mymodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=["accuracy"])

# fitting the train set in the model

mymodel.fit(x = X_train, 
          y = y_train, 
          epochs = 25,
          batch_size = 10240, 
          validation_data = (X_test, y_test), 
          callbacks = None)

# the model summary

mymodel.summary()

# Classification report for the standard neural network model

from sklearn.metrics import classification_report, confusion_matrix
predictions = mymodel.predict_classes(X_test)
print(classification_report(y_test, predictions))

# Confusion matrix for the standard neural network model

confusion_matrix(y_test,predictions)

# RMSE for training data and test data

from sklearn import metrics

pred = mymodel.predict(X_train)
score = np.sqrt(metrics.mean_squared_error(pred, y_train))
print(f"legitimate Score (RMSE): {score}")

pred = mymodel.predict(X_test)
score = np.sqrt(metrics.mean_squared_error(pred, y_test))
print(f"anomaly Score (RMSE): {score}")